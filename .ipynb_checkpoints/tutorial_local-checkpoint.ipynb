{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-pVhOfzLx9us"
   },
   "source": [
    "#Waymo Open Dataset Tutorial (using local Jupyter kernel)\n",
    "\n",
    "- Website: https://waymo.com/open\n",
    "- GitHub: https://github.com/waymo-research/waymo-open-dataset\n",
    "\n",
    "This tutorial demonstrates how to use the Waymo Open Dataset with two frames of data. Visit the [Waymo Open Dataset Website](https://waymo.com/open) to download the full dataset.\n",
    "\n",
    "To use:\n",
    "1. checkout `waymo_open_dataset` (need to run once):\n",
    "   ```\n",
    "   git clone https://github.com/waymo-research/waymo-open-dataset.git waymo-open-dataset-repo\n",
    "   cd waymo-open-dataset-repo\n",
    "   ```\n",
    "2. build docker container (need to run once):\n",
    "   ```\n",
    "   docker build --tag=open_dataset -f tutorial/cpu-jupyter.Dockerfile .\n",
    "   ```\n",
    "3. start Jupyter kernel inside the docker container:\n",
    "   ```\n",
    "   docker run -p 8888:8888 open_dataset\n",
    "   ```\n",
    "4. connect the notebook to the local port `8888`.\n",
    "\n",
    "Uncheck the box \"Reset all runtimes before running\" if you run this colab directly from the remote kernel. Alternatively, you can make a copy before trying to run it by following \"File > Save copy in Drive ...\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P8pO1b1EALPA"
   },
   "source": [
    "### Metrics computation\n",
    "The core metrics computation library is written in C++, so it can be extended to other programming languages. It can compute detection metrics (mAP) and tracking metrics (MOTA). See more information about the metrics on the [website](https://waymo.com/open/next/).\n",
    "\n",
    "We provide command line tools and TensorFlow ops to call the detection metrics library to compute detection metrics. We will provide a similar wrapper for tracking metrics library in the future. You are welcome to contribute your wrappers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UIBufmNJBdGR"
   },
   "source": [
    "#### Command line detection metrics computation\n",
    "\n",
    "The command takes a pair of files for prediction and ground truth. Read the comment in waymo_open_dataset/metrics/tools/compute_detection_metrics_main.cc for details of the data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JZ96ro4vp9tj"
   },
   "outputs": [],
   "source": [
    "# copybara removed file resource import\n",
    "import os\n",
    "\n",
    "if os.path.exists('tutorial_local.ipynb'):\n",
    "    # in case it is executed as a Jupyter notebook from the tutorial folder.\n",
    "    os.chdir('../')\n",
    "\n",
    "\n",
    "fake_predictions_path = '{pyglib_resource}waymo_open_dataset/metrics/tools/fake_predictions.bin'.format(pyglib_resource='')\n",
    "fake_ground_truths_path = '{pyglib_resource}waymo_open_dataset/metrics/tools/fake_ground_truths.bin'.format(pyglib_resource='')\n",
    "bin_path = '{pyglib_resource}waymo_open_dataset/metrics/tools/compute_detection_metrics_main'.format(pyglib_resource='')\n",
    "frames_path = '{pyglib_resource}tutorial/frames'.format(pyglib_resource='')\n",
    "point_cloud_path = '{pyglib_resource}tutorial/3d_point_cloud.png'.format(pyglib_resource='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GFqlUjAH6V9V"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'waymo_open_dataset' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!{bin_path} {fake_predictions_path} {fake_ground_truths_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_FpcGDRnAElo"
   },
   "source": [
    "### Load waymo_open_dataset package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZwnPUOgVAHec"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from waymo_open_dataset.utils import frame_utils\n",
    "from waymo_open_dataset import dataset_pb2 as open_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ibor0U9XBlX6"
   },
   "source": [
    "## Read one frame\n",
    "\n",
    "Each file in the dataset is a sequence of frames ordered by frame start timestamps. We have extracted two frames from the dataset to demonstrate the dataset format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "29uZtYLJBx2r"
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "NewRandomAccessFile failed to Create/Open: tutorial/frames : The system cannot find the path specified.\r\n; No such process [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mTFRecordDataset(frames_path, compression_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[0;32m      3\u001b[0m     frame \u001b[38;5;241m=\u001b[39m open_dataset\u001b[38;5;241m.\u001b[39mFrame()\n\u001b[0;32m      4\u001b[0m     frame\u001b[38;5;241m.\u001b[39mParseFromString(\u001b[38;5;28mbytearray\u001b[39m(data\u001b[38;5;241m.\u001b[39mnumpy()))\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\its_group\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    765\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    767\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\its_group\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 749\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    754\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\its_group\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3016\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3014\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3015\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3016\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3017\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   3018\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\its_group\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7163\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7164\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: NewRandomAccessFile failed to Create/Open: tutorial/frames : The system cannot find the path specified.\r\n; No such process [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.TFRecordDataset(frames_path, compression_type='')\n",
    "for data in dataset:\n",
    "    frame = open_dataset.Frame()\n",
    "    frame.ParseFromString(bytearray(data.numpy()))\n",
    "    break\n",
    "\n",
    "#(range_images, camera_projections, range_image_top_pose) = (\n",
    "#    frame_utils.parse_range_image_and_camera_projection(frame))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eorb6V2qznV_"
   },
   "source": [
    "###Examine frame context\n",
    "\n",
    "Refer to [dataset.proto](https://github.com/waymo-research/waymo-open-dataset/blob/master/waymo_open_dataset/dataset.proto) for the data format. The context contains shared information among all frames in the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZotEevt7S0fE"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mframe\u001b[49m\u001b[38;5;241m.\u001b[39mcontext)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'frame' is not defined"
     ]
    }
   ],
   "source": [
    "print(frame.context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DjdoulAnU1LK"
   },
   "source": [
    "##Visualize Camera Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ne4-TpYLVCwi"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m   plt\u001b[38;5;241m.\u001b[39mgrid(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m   plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mframe\u001b[49m\u001b[38;5;241m.\u001b[39mimages):\n\u001b[0;32m     13\u001b[0m   image_show(image\u001b[38;5;241m.\u001b[39mimage, open_dataset\u001b[38;5;241m.\u001b[39mCameraName\u001b[38;5;241m.\u001b[39mName\u001b[38;5;241m.\u001b[39mName(image\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m     14\u001b[0m              [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'frame' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(25, 20))\n",
    "\n",
    "def image_show(data, name, layout, cmap=None):\n",
    "  \"\"\"Show an image.\"\"\"\n",
    "  plt.subplot(*layout)\n",
    "  plt.imshow(tf.image.decode_jpeg(data), cmap=cmap)\n",
    "  plt.title(name)\n",
    "  plt.grid(False)\n",
    "  plt.axis('off')\n",
    "\n",
    "for index, image in enumerate(frame.images):\n",
    "  image_show(image.image, open_dataset.CameraName.Name.Name(image.name),\n",
    "             [3, 3, index+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JPc-xBE6VMHi"
   },
   "source": [
    "##Visualize Range Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mwZ4xcsHVO1V"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 44\u001b[0m\n\u001b[0;32m     40\u001b[0m   plot_range_image_helper(range_image_intensity\u001b[38;5;241m.\u001b[39mnumpy(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintensity\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     41\u001b[0m                    [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m1\u001b[39m, layout_index_start \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m], vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m   plot_range_image_helper(range_image_elongation\u001b[38;5;241m.\u001b[39mnumpy(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124melongation\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     43\u001b[0m                    [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m1\u001b[39m, layout_index_start \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m], vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m \u001b[43mframe\u001b[49m\u001b[38;5;241m.\u001b[39mlasers\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m laser: laser\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m     45\u001b[0m show_range_image(get_range_image(open_dataset\u001b[38;5;241m.\u001b[39mLaserName\u001b[38;5;241m.\u001b[39mTOP, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     46\u001b[0m show_range_image(get_range_image(open_dataset\u001b[38;5;241m.\u001b[39mLaserName\u001b[38;5;241m.\u001b[39mTOP, \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'frame' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 6400x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(64, 20))\n",
    "def plot_range_image_helper(data, name, layout, vmin = 0, vmax=1, cmap='gray'):\n",
    "  \"\"\"Plots range image.\n",
    "\n",
    "  Args:\n",
    "    data: range image data\n",
    "    name: the image title\n",
    "    layout: plt layout\n",
    "    vmin: minimum value of the passed data\n",
    "    vmax: maximum value of the passed data\n",
    "    cmap: color map\n",
    "  \"\"\"\n",
    "  plt.subplot(*layout)\n",
    "  plt.imshow(data, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "  plt.title(name)\n",
    "  plt.grid(False)\n",
    "  plt.axis('off')\n",
    "\n",
    "def get_range_image(laser_name, return_index):\n",
    "  \"\"\"Returns range image given a laser name and its return index.\"\"\"\n",
    "  return range_images[laser_name][return_index]\n",
    "\n",
    "def show_range_image(range_image, layout_index_start = 1):\n",
    "  \"\"\"Shows range image.\n",
    "\n",
    "  Args:\n",
    "    range_image: the range image data from a given lidar of type MatrixFloat.\n",
    "    layout_index_start: layout offset\n",
    "  \"\"\"\n",
    "  range_image_tensor = tf.convert_to_tensor(range_image.data)\n",
    "  range_image_tensor = tf.reshape(range_image_tensor, range_image.shape.dims)\n",
    "  lidar_image_mask = tf.greater_equal(range_image_tensor, 0)\n",
    "  range_image_tensor = tf.where(lidar_image_mask, range_image_tensor,\n",
    "                                tf.ones_like(range_image_tensor) * 1e10)\n",
    "  range_image_range = range_image_tensor[...,0] \n",
    "  range_image_intensity = range_image_tensor[...,1]\n",
    "  range_image_elongation = range_image_tensor[...,2]\n",
    "  plot_range_image_helper(range_image_range.numpy(), 'range',\n",
    "                   [8, 1, layout_index_start], vmax=75, cmap='gray')\n",
    "  plot_range_image_helper(range_image_intensity.numpy(), 'intensity',\n",
    "                   [8, 1, layout_index_start + 1], vmax=1.5, cmap='gray')\n",
    "  plot_range_image_helper(range_image_elongation.numpy(), 'elongation',\n",
    "                   [8, 1, layout_index_start + 2], vmax=1.5, cmap='gray')\n",
    "frame.lasers.sort(key=lambda laser: laser.name)\n",
    "show_range_image(get_range_image(open_dataset.LaserName.TOP, 0), 1)\n",
    "show_range_image(get_range_image(open_dataset.LaserName.TOP, 1), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "17Lwd2nVpex7"
   },
   "source": [
    "##Point Cloud Conversion and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XIEDW1pfpmd-"
   },
   "outputs": [],
   "source": [
    "points, cp_points = frame_utils.convert_range_image_to_point_cloud(frame,\n",
    "                                                       range_images,\n",
    "                                                       camera_projections,\n",
    "                                                       range_image_top_pose)\n",
    "points_ri2, cp_points_ri2 = frame_utils.convert_range_image_to_point_cloud(\n",
    "    frame,\n",
    "    range_images,\n",
    "    camera_projections,\n",
    "    range_image_top_pose,\n",
    "    ri_index=1)\n",
    "\n",
    "# 3d points in vehicle frame.\n",
    "points_all = np.concatenate(points, axis=0)\n",
    "points_all_ri2 = np.concatenate(points_ri2, axis=0)\n",
    "# camera projection corresponding to each point.\n",
    "cp_points_all = np.concatenate(cp_points, axis=0)\n",
    "cp_points_all_ri2 = np.concatenate(cp_points_ri2, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5MAKwTRWz3af"
   },
   "source": [
    "###Examine number of points in each lidar sensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E5_e4BCAGfYX"
   },
   "source": [
    "First return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bpsAJp2CqKrE"
   },
   "outputs": [],
   "source": [
    "print(points_all.shape)\n",
    "print(cp_points_all.shape)\n",
    "print(points_all[0:2])\n",
    "for i in range(5):\n",
    "  print(points[i].shape)\n",
    "  print(cp_points[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3cdlVYFGiE_"
   },
   "source": [
    "Second return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QX6aj2EDGlRo"
   },
   "outputs": [],
   "source": [
    "print(points_all_ri2.shape)\n",
    "print(cp_points_all_ri2.shape)\n",
    "print(points_all_ri2[0:2])\n",
    "for i in range(5):\n",
    "  print(points_ri2[i].shape)\n",
    "  print(cp_points_ri2[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PCj3SDbuq9Nr"
   },
   "source": [
    "###Show point cloud\n",
    "3D point clouds are rendered using an internal tool, which is unfortunately not publicly available yet. Here is an example of what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K8VFnGnOq6cO"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: 'tutorial/3d_point_cloud.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\envs\\its_group\\lib\\site-packages\\IPython\\core\\display.py:1045\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1045\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m \u001b[43mb2a_base64\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\envs\\its_group\\lib\\site-packages\\IPython\\core\\formatters.py:972\u001b[0m, in \u001b[0;36mMimeBundleFormatter.__call__\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    969\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m    971\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 972\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\its_group\\lib\\site-packages\\IPython\\core\\display.py:1035\u001b[0m, in \u001b[0;36mImage._repr_mimebundle_\u001b[1;34m(self, include, exclude)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m   1034\u001b[0m     mimetype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mimetype\n\u001b[1;32m-> 1035\u001b[0m     data, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_and_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43malways_both\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metadata:\n\u001b[0;32m   1037\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m {mimetype: metadata}\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\its_group\\lib\\site-packages\\IPython\\core\\display.py:1047\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m b2a_base64(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1047\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1048\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m md \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file or directory: 'tutorial/3d_point_cloud.png'"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: 'tutorial/3d_point_cloud.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\envs\\its_group\\lib\\site-packages\\IPython\\core\\display.py:1045\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1045\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m \u001b[43mb2a_base64\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\envs\\its_group\\lib\\site-packages\\IPython\\core\\formatters.py:342\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    340\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\its_group\\lib\\site-packages\\IPython\\core\\display.py:1067\u001b[0m, in \u001b[0;36mImage._repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repr_png_\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FMT_PNG:\n\u001b[1;32m-> 1067\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_and_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\its_group\\lib\\site-packages\\IPython\\core\\display.py:1047\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m b2a_base64(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1047\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1048\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m md \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file or directory: 'tutorial/3d_point_cloud.png'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(point_cloud_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HiGOSt4mr0xA"
   },
   "source": [
    "##Visualize Camera Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yRMUN-hur9wO"
   },
   "outputs": [],
   "source": [
    "images = sorted(frame.images, key=lambda i:i.name)\n",
    "cp_points_all_concat = np.concatenate([cp_points_all, points_all], axis=-1)\n",
    "cp_points_all_concat_tensor = tf.constant(cp_points_all_concat)\n",
    "\n",
    "# The distance between lidar points and vehicle frame origin.\n",
    "points_all_tensor = tf.norm(points_all, axis=-1, keepdims=True)\n",
    "cp_points_all_tensor = tf.constant(cp_points_all, dtype=tf.int32)\n",
    "\n",
    "mask = tf.equal(cp_points_all_tensor[..., 0], images[0].name)\n",
    "\n",
    "cp_points_all_tensor = tf.cast(tf.gather_nd(\n",
    "    cp_points_all_tensor, tf.where(mask)), dtype=tf.float32)\n",
    "points_all_tensor = tf.gather_nd(points_all_tensor, tf.where(mask))\n",
    "\n",
    "projected_points_all_from_raw_data = tf.concat(\n",
    "    [cp_points_all_tensor[..., 1:3], points_all_tensor], axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Invsxz0xsXNA"
   },
   "outputs": [],
   "source": [
    "def rgba(r):\n",
    "  \"\"\"Generates a color based on range.\n",
    "\n",
    "  Args:\n",
    "    r: the range value of a given point.\n",
    "  Returns:\n",
    "    The color for a given range\n",
    "  \"\"\"\n",
    "  c = plt.get_cmap('jet')((r % 20.0) / 20.0)\n",
    "  c = list(c)\n",
    "  c[-1] = 0.5  # alpha\n",
    "  return c\n",
    "\n",
    "def plot_image(camera_image):\n",
    "  \"\"\"Plot a cmaera image.\"\"\"\n",
    "  plt.figure(figsize=(20, 12))\n",
    "  plt.imshow(tf.image.decode_jpeg(camera_image.image))\n",
    "  plt.grid(\"off\")\n",
    "\n",
    "def plot_points_on_image(projected_points, camera_image, rgba_func,\n",
    "                         point_size=5.0):\n",
    "  \"\"\"Plots points on a camera image.\n",
    "\n",
    "  Args:\n",
    "    projected_points: [N, 3] numpy array. The inner dims are\n",
    "      [camera_x, camera_y, range].\n",
    "    camera_image: jpeg encoded camera image.\n",
    "    rgba_func: a function that generates a color from a range value.\n",
    "    point_size: the point size.\n",
    "\n",
    "  \"\"\"\n",
    "  plot_image(camera_image)\n",
    "\n",
    "  xs = []\n",
    "  ys = []\n",
    "  colors = []\n",
    "\n",
    "  for point in projected_points:\n",
    "    xs.append(point[0])  # width, col\n",
    "    ys.append(point[1])  # height, row\n",
    "    colors.append(rgba_func(point[2]))\n",
    "\n",
    "  plt.scatter(xs, ys, c=colors, s=point_size, edgecolors=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fx7mUQM2saI-"
   },
   "outputs": [],
   "source": [
    "plot_points_on_image(projected_points_all_from_raw_data,\n",
    "                     images[0], rgba, point_size=5.0)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "",
    "kind": "local"
   },
   "name": "Waymo Open Dataset Tutorial (using local Jupyter kernel).ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
