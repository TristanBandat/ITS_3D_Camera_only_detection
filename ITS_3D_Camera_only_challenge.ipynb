{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4e9fe20-fb22-4330-995f-c6a08d991992",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,170)\">ITS 3D Camery only challenge</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7151c6e1-b7fe-45e1-bff1-247c0d19e684",
   "metadata": {},
   "source": [
    "The task was to predict cars in an image without the availability of LiDAR sensing. The model should output for every pixel if the pixel belongs to a car (1) or not (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355850c9-9fa3-4691-8e67-1dc82a8d74a0",
   "metadata": {},
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Dataset</h2>\n",
    "Here is an example of an image with the ground truth:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906e757c-a475-4a27-8db5-dc73c3c8f060",
   "metadata": {},
   "source": [
    "![input and output for a random image in the test dataset](https://i.imgur.com/GD8FcB7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ff293c-f62d-4413-97a3-34294544629d",
   "metadata": {},
   "source": [
    "The yellow area belongs to the car (=1).\n",
    "The model should predict the yellow area, which belongs to the car.\n",
    "For every pixel the target tensor contains either the value 0(=no car) or 1(=car)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944fe06f-3252-45bb-886c-9bc7d88498aa",
   "metadata": {},
   "source": [
    "In our case the data isn't that beatiful and we only have boxes given, where the car is included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4861b76a-2469-4432-81d5-41348f6d8d70",
   "metadata": {},
   "source": [
    "![Car Boxes](./images_notebook/example_boxes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86a2270-d8ab-4da0-a959-0015af569e98",
   "metadata": {},
   "source": [
    "Therefore, our Target are basically boxes where the car is included. Here is an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21b942e-2e5c-45a4-aac3-076bed644500",
   "metadata": {},
   "source": [
    "![Input1](./images_notebook/example_image_input.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bb508e-690b-43fc-a86d-569b8f0a3121",
   "metadata": {},
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Approach</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f2db8b-5fe9-44ea-a989-a7a9440e790b",
   "metadata": {},
   "source": [
    "First lets import the neceassary packages. We are using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89c957a0-0e8d-44b4-abb3-6a6f34d0ddc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jakob\\miniconda3\\envs\\its_group\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from CNN import CNN\n",
    "from UNet import UNet\n",
    "from train import train\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from dataloader import get_dataloaders\n",
    "from ImageDataset import ImageDataset\n",
    "from evaluate import evaluate_model\n",
    "from plot import plot\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43b2cc5-2920-4d0e-b14b-45c7df7a4362",
   "metadata": {},
   "source": [
    "Next we load one of our Models, in this case our UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c594abb2-5958-4d40-b798-acf049ca9ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet(n_channels=1, n_classes=1, bilinear=False)  # classes are 1 and 0 (car, no car) therefore 1 class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc0f475-ba4b-4cc2-b7ae-52dee91d8ee0",
   "metadata": {},
   "source": [
    "Next we define some Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e87321d0-25f4-43b0-94f7-e5edcb1a80a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "weight_decay = 1e-5\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "batchsize = 16\n",
    "\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "loss_fn_new = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "nupdates = 5000\n",
    "\n",
    "testset_ratio = 1 / 5\n",
    "\n",
    "validset_ratio = 1 / 5\n",
    "\n",
    "num_workers = 0\n",
    "\n",
    "seed = 1234\n",
    "\n",
    "resultpath = 'results/unet'\n",
    "\n",
    "datapath = os.path.join(os.getcwd(), 'data/new_data.pkl')\n",
    "\n",
    "print_stats_at = 100  # print status to tensorboard every x updates\n",
    "validate_at = 200  # evaluate model on validation set and check for new best model every x updates\n",
    "plot_images_at = 50 # plot model every 100 updates\n",
    "\n",
    "np.random.seed(seed=seed)\n",
    "torch.manual_seed(seed=seed);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a0131-937a-440a-9613-599b129aabba",
   "metadata": {},
   "source": [
    "Next we load our ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0993459b-4a7e-46ef-ab23-8da3e7024b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = ImageDataset(frame_path=datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd05ab6e-7a30-4fe6-a27e-cfa692b7f8e8",
   "metadata": {},
   "source": [
    "From the dataset we create our train, test and validation set loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acd974e1-2191-4f22-a3fa-78b8279fbae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = get_dataloaders(image_dataset, testset_ratio, validset_ratio, batchsize,\n",
    "                                                              num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34cc226-da75-4be9-a1d5-4a0c7680aa7f",
   "metadata": {},
   "source": [
    "Next we initialize our tensorboard writer. Tensorboard is a great way to provide visualization and check how our Model is doing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25a6a17f-e53b-47a6-bad4-859cf70201d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jakob\\miniconda3\\envs\\its_group\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(log_dir=os.path.join(resultpath, 'tensorboard'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad05115-32ce-43dc-b4f0-0c6f3f35b170",
   "metadata": {},
   "source": [
    "We use early stopping, which means our training stops if the validation loss doesn't increase anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d783034a-d0a0-44e3-b842-fd391b9ffed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "update = 0  # current update counter\n",
    "best_validation_loss = np.inf  # best validation loss so far\n",
    "no_update_counter = 0  # counter for how many updates have passed without a new best validation loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1df8b63-685c-4df7-9f89-6bc8753708bd",
   "metadata": {},
   "source": [
    "We use the adam optimizer and the BCE with logits loss, which combines BCE with a sigmoid layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2799953-6ca5-42f4-9dc8-1a191507e7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move network to device\n",
    "net.to(device)\n",
    "\n",
    "# get loss\n",
    "loss_fn = loss_fn_new\n",
    "\n",
    "# get adam optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# Save initial model as \"best\" model (will be overwritten later)\n",
    "torch.save(net, os.path.join(resultpath, 'best_model.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d225b1-1573-439f-9f30-021acf4ce666",
   "metadata": {},
   "source": [
    "This is our evaluation function. It returns the average loss for a given dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "908450ac-4842-4466-a6a6-9593f5349263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, device: torch.device, loss_fn):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            image_array = batch['image']\n",
    "            target_array = batch['boxes']\n",
    "\n",
    "            # move to device\n",
    "            image_array = image_array.to(device, dtype=torch.float32)\n",
    "            target_array = target_array.to(device, dtype=torch.float32)\n",
    "\n",
    "            # get output\n",
    "            output = model(image_array)\n",
    "\n",
    "            loss += loss_fn(output, target_array)\n",
    "\n",
    "    model.train() # setting model back to training mode\n",
    "    loss /= len(dataloader)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f4197c-b2c1-429d-b159-d0633b7216c4",
   "metadata": {},
   "source": [
    "Now comes our training loop. The structure is rather basic. Our training ends if the maximum number of updates is reached or the validation loss hasn't increased after 3 checks.\n",
    "We first load the data and pass it to the model. We calculate the weights update and check if our Model performs better than before with the help of the validation loss. If this is the case, the new model is saved. We also write some statistics to our tensorboard and the console. In addition, we create some plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e69c4efe-ed78-4b75-8b18-39b0fd73bdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.61546:   1%|▋                                                                | 50/5000 [00:42<48:16,  1.71it/s]C:\\Users\\jakob\\miniconda3\\envs\\its_group\\lib\\site-packages\\torch\\nn\\functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "loss: 0.56803:   4%|██▌                                                             | 200/5000 [02:07<41:59,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model found, saving...\n",
      "Finished saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.53395:  12%|███████▋                                                        | 600/5000 [08:39<44:02,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model found, saving...\n",
      "Finished saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.47235:  20%|████████████▌                                                  | 1000/5000 [13:20<43:24,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model found, saving...\n",
      "Finished saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.38343: 100%|█████████████████████████████████████████████████████████████| 5000/5000 [1:00:00<00:00,  1.91it/s]"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "\n",
    "# initialize progressbar\n",
    "update_progessbar = tqdm.tqdm(total=nupdates, desc=f\"loss: {np.nan:7.5f}\", position=0)  # progressbar\n",
    "while update < nupdates and no_update_counter < 3: # stop training if val loss doesn't increase after 3 times or nupdates is reached\n",
    "    for batch in train_loader:\n",
    "\n",
    "        # get data\n",
    "        image_array = batch['image']\n",
    "        target_array = batch['boxes']\n",
    "            \n",
    "        # move image and target to device\n",
    "        image_array = image_array.to(device, dtype=torch.float32)\n",
    "        target_array = target_array.to(device, dtype=torch.float32)\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = net(image_array)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(output, target_array)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar\n",
    "        update_progessbar.set_description(f\"loss: {loss.item():7.5f}\")\n",
    "        update_progessbar.update(1)\n",
    "\n",
    "        # Evaluate model on validation set\n",
    "        if (update + 1) % validate_at == 0 and update > 0:\n",
    "            val_loss = evaluate_model(net, dataloader=valid_loader, device=device, loss_fn=loss_fn)\n",
    "            writer.add_scalar(tag=\"validation/loss\", scalar_value=val_loss, global_step=update)\n",
    "            # Add weights as arrays to tensorboard\n",
    "            for i, param in enumerate(net.parameters()):\n",
    "                writer.add_histogram(tag=f'validation/param_{i}', values=param,\n",
    "                                        global_step=update)\n",
    "            # Add gradients as arrays to tensorboard\n",
    "            for i, param in enumerate(net.parameters()):\n",
    "                writer.add_histogram(tag=f'validation/gradients_{i}',\n",
    "                                         values=param.grad.cpu(),\n",
    "                                         global_step=update)\n",
    "            # Save best model for early stopping\n",
    "            if best_validation_loss > val_loss:\n",
    "                no_update_counter = 0\n",
    "                best_validation_loss = val_loss\n",
    "                print(\"\\nNew best model found, saving...\")\n",
    "                torch.save(net, os.path.join(resultpath, 'best_model.pt'))\n",
    "                print(\"Finished saving\")\n",
    "\n",
    "        # Print current status and score\n",
    "        if (update + 1) % print_stats_at == 0:\n",
    "            writer.add_scalar(tag=\"training/loss\",\n",
    "                                  scalar_value=loss.cpu(),\n",
    "                                  global_step=update)\n",
    "\n",
    "        if (update + 1) % plot_images_at == 0:\n",
    "            prediction = (torch.nn.functional.sigmoid(output) > 0.5).float()\n",
    "            plot(image_array.detach().cpu().numpy()[0, 0], target_array.detach().cpu().numpy()[0, 0],\n",
    "                    prediction.detach().cpu().numpy()[0, 0], os.path.join(resultpath, \"plots\"), update)\n",
    "\n",
    "        update += 1\n",
    "        if update >= nupdates or no_update_counter >= 3:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5a464a-da14-431c-89f5-5ef51e1c5c78",
   "metadata": {},
   "source": [
    "After the training we evaluate our model on our training, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "730cd759-f8ab-4aee-86c1-22a8dc7e9a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing scores for best model\n",
      "Scores:\n",
      "test loss: 0.5455533266067505\n",
      "validation loss: 0.5114364624023438\n",
      "training loss: 0.490740031003952\n"
     ]
    }
   ],
   "source": [
    "print(f\"Computing scores for best model\")\n",
    "net = torch.load(os.path.join(resultpath, 'best_model.pt'))\n",
    "test_loss = evaluate_model(net, dataloader=test_loader, device=device, loss_fn=loss_fn)\n",
    "val_loss = evaluate_model(net, dataloader=valid_loader, device=device, loss_fn=loss_fn)\n",
    "train_loss = evaluate_model(net, dataloader=train_loader, device=device, loss_fn=loss_fn)\n",
    "\n",
    "print(f\"Scores:\")\n",
    "print(f\"test loss: {test_loss}\")\n",
    "print(f\"validation loss: {val_loss}\")\n",
    "print(f\"training loss: {train_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d7aff5-cd23-46f8-855c-77e862ec7be0",
   "metadata": {},
   "source": [
    "<h2> Plots</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8e3d6e-68d5-46aa-93d5-1a11ce1dd2bd",
   "metadata": {},
   "source": [
    "Here we can see some plots after training:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffa7e06-2d0f-4833-831a-4010064a260f",
   "metadata": {},
   "source": [
    "![Ouptut1](./images_notebook/example_output_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd803b0-f574-417d-ab26-2760c4b900d6",
   "metadata": {},
   "source": [
    "![Ouptut2](./images_notebook/example_output_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d542c523-d418-4e25-abe9-4770e1aa574e",
   "metadata": {},
   "source": [
    "![Ouptut3](./images_notebook/example_output_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd430717-f1e2-4405-bc9a-cdcaaef8ed8e",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20951afb-40ef-40db-bf67-89961995b169",
   "metadata": {},
   "source": [
    "Like it can be seen in the images above, the model somehow makes a let's say acceptable job, knowing that the target image does not really represent the situation correctly. For the last image, we assume that the sequence of images is rather constant, that's why the prediction on such an input is pretty good. This also kind of shows that the model would make a good job, if there would've been totally right target arrays."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
