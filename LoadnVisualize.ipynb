{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81213e2-2eef-4b19-bb0d-7ac6a19aa98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not necessary any more: Just use the files in the GitHub repo ~ Jakob: 28.11.2022 08:45\n",
    "\n",
    "#!rm -rf waymo-od > /dev/null\n",
    "#!git clone https://github.com/waymo-research/waymo-open-dataset.git waymo-od\n",
    "#!cd waymo-od && git branch -a\n",
    "#!cd waymo-od && git checkout remotes/origin/r1.0\n",
    "#!pip3 install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3898f05e-382b-4fcd-8411-1c141595ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those commands were only needed once. Just use the GitHub repo ~ Jakob: 28.11.2022 08:48\n",
    "\n",
    "# protoc waymo_open_dataset/dataset.proto --python_out=.\n",
    "# protoc waymo_open_dataset/label.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8549148-61a1-49b5-96b8-a2ff9910c35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "\n",
    "#!pip3 install waymo-open-dataset\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from waymo_open_dataset.utils import range_image_utils\n",
    "from waymo_open_dataset.utils import transform_utils\n",
    "from waymo_open_dataset.utils import  frame_utils\n",
    "from waymo_open_dataset import dataset_pb2 as open_dataset\n",
    "\n",
    "\n",
    "# TODO: Use PyTorch instead of tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3053148f-74f3-4cda-92ca-cbdc42e43657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data sample data from the tutorial. ~ Jakob: 28.11.2022 09:36\n",
    "\n",
    "#path = r'{pyglib_resource}data/'.format(pyglib_resource='')\n",
    "path = r'{pyglib_resource}tutorial/frames'.format(pyglib_resource='')\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(path, compression_type='')\n",
    "for data in dataset:\n",
    "    frame = open_dataset.Frame()\n",
    "    frame.ParseFromString(bytearray(data.numpy()))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e963293f-9e16-4176-81fb-4b454ba2910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "def image_show(data, name, layout, cmap=None):\n",
    "  \"\"\"Show an image.\"\"\"\n",
    "  plt.subplot(*layout)\n",
    "  plt.imshow(tf.image.decode_jpeg(data), cmap=cmap)\n",
    "  plt.title(name)\n",
    "  plt.grid(False)\n",
    "  plt.axis('off')\n",
    "\n",
    "for index, image in enumerate(frame.images):\n",
    "  image_show(image.image, open_dataset.CameraName.Name.Name(image.name),\n",
    "             [3, 3, index+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c751cfb-2f26-40a5-838d-78144f8aac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not working yet. I tried to visualize the data of one of the training samples. But it didn't work out yet ~ Jakob 28.11.2022 09:43\n",
    "\n",
    "from google.protobuf.json_format import MessageToJson\n",
    "import json\n",
    "\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(r'data/training_20s.tfrecord-00000-of-01000')\n",
    "\n",
    "for d in dataset:\n",
    "    ex = tf.train.Example()\n",
    "    ex.ParseFromString(d.numpy())\n",
    "    m = json.loads(MessageToJson(ex))\n",
    "    #print(m)\n",
    "\n",
    "#for data in tf.python_io.tf_record_iterator(r'{pyglib_resource}training_20s'.format(pyglib_resource='')):\n",
    "#    print(tf.train.Example.FromString(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73841974-9228-4295-a388-7a17c4e0d957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not working yet. ~ Jakob 28.11.2022 09:43\n",
    "\n",
    "plt.figure(figsize=(64, 20))\n",
    "def plot_range_image_helper(data, name, layout, vmin = 0, vmax=1, cmap='gray'):\n",
    "  \"\"\"Plots range image.\n",
    "\n",
    "  Args:\n",
    "    data: range image data\n",
    "    name: the image title\n",
    "    layout: plt layout\n",
    "    vmin: minimum value of the passed data\n",
    "    vmax: maximum value of the passed data\n",
    "    cmap: color map\n",
    "  \"\"\"\n",
    "  plt.subplot(*layout)\n",
    "  plt.imshow(data, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "  plt.title(name)\n",
    "  plt.grid(False)\n",
    "  plt.axis('off')\n",
    "\n",
    "def get_range_image(laser_name, return_index):\n",
    "  \"\"\"Returns range image given a laser name and its return index.\"\"\"\n",
    "  return range_images[laser_name][return_index]\n",
    "\n",
    "def show_range_image(range_image, layout_index_start = 1):\n",
    "  \"\"\"Shows range image.\n",
    "\n",
    "  Args:\n",
    "    range_image: the range image data from a given lidar of type MatrixFloat.\n",
    "    layout_index_start: layout offset\n",
    "  \"\"\"\n",
    "  range_image_tensor = tf.convert_to_tensor(range_image.data)\n",
    "  range_image_tensor = tf.reshape(range_image_tensor, range_image.shape.dims)\n",
    "  lidar_image_mask = tf.greater_equal(range_image_tensor, 0)\n",
    "  range_image_tensor = tf.where(lidar_image_mask, range_image_tensor,\n",
    "                                tf.ones_like(range_image_tensor) * 1e10)\n",
    "  range_image_range = range_image_tensor[...,0] \n",
    "  range_image_intensity = range_image_tensor[...,1]\n",
    "  range_image_elongation = range_image_tensor[...,2]\n",
    "  plot_range_image_helper(range_image_range.numpy(), 'range',\n",
    "                   [8, 1, layout_index_start], vmax=75, cmap='gray')\n",
    "  plot_range_image_helper(range_image_intensity.numpy(), 'intensity',\n",
    "                   [8, 1, layout_index_start + 1], vmax=1.5, cmap='gray')\n",
    "  plot_range_image_helper(range_image_elongation.numpy(), 'elongation',\n",
    "                   [8, 1, layout_index_start + 2], vmax=1.5, cmap='gray')\n",
    "frame.lasers.sort(key=lambda laser: laser.name)\n",
    "show_range_image(get_range_image(open_dataset.LaserName.TOP, 0), 1)\n",
    "show_range_image(get_range_image(open_dataset.LaserName.TOP, 1), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f9c9fa-c70a-449a-aeb7-0e8a2b07e068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
